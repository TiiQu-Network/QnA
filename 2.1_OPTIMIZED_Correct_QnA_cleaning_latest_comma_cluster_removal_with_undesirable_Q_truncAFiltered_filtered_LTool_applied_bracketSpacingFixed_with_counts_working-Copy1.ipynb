{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "655db856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspellchecker\n",
      "  Downloading pyspellchecker-0.7.2-py3-none-any.whl (3.4 MB)\n",
      "Installing collected packages: pyspellchecker\n",
      "Successfully installed pyspellchecker-0.7.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae3e28b",
   "metadata": {},
   "source": [
    "###### Counting the total number of all errors including undesirable Typos, QnAs and truncated QnAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4445a7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Question  6 non-null      object\n",
      " 1   Answer    6 non-null      object\n",
      "dtypes: object(2)\n",
      "memory usage: 224.0+ bytes\n",
      "['Question', 'Answer']\n",
      "Corresponding Question 1: What are the limitations of this study?\n",
      "Truncated Answer  1: The limitations of this study avaliable include the exclusion of Love Matters social media platforms and offline components, as well as the dependency on user cookie settings and limitations in recognizing source traffic \n",
      "\n",
      "Corresponding Question 3: What is the aim of new vaccine development?\n",
      "Truncated Answer  3: The aim of new,,,, vaccine development is to enhance maternal immunization, e.g. for group B streptococcus and respiratory syncytial virus, and to reduce serious morbidity and mortality in \n",
      "\n",
      "Number of rows in filtered data: 2\n",
      "Number of rows in remaining data: 2\n",
      "\n",
      "Original text: Respiratory infections and sepsis are among the leading causes of neonatal deaths in 195 countries    across the world. This is  ,,,, gallic() rerun or odds     avaliable?\n",
      "Corrected text: Respiratory infections and sepsis are among the leading causes of neonatal deaths in 195 countries    across the world. This is  ,  gallic() rerun or odds     avaliable?\n",
      "Total comma count: 0\n",
      "What are the leading causes of neonatal deaths in 195 countries?\n",
      "Respiratory infections and sepsis are among the leading causes of neonatal deaths in 195 countries across the world. This is , Gallic () rerun or odds available?\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import language_tool_python\n",
    "import time\n",
    "import cProfile\n",
    "\n",
    "def count_multiple_commas(text):\n",
    "    pattern = re.compile(r',{2,}')\n",
    "    return len(re.findall(pattern, text))\n",
    "\n",
    "def replace_multiple_commas(text):\n",
    "    pattern = re.compile(r',{2,}')\n",
    "    corrected_text = re.sub(pattern, ', ', text)\n",
    "    if corrected_text != text:\n",
    "        print(f\"\\nOriginal text: {text}\")\n",
    "        print(f\"Corrected text: {corrected_text}\")\n",
    "    return corrected_text\n",
    "\n",
    "def comma_cluster_removal_df(df):\n",
    "    total_comma_count = 0\n",
    "\n",
    "    for column in df.columns:\n",
    "        df[column] = df[column].apply(replace_multiple_commas)\n",
    "        total_comma_count += df[column].apply(count_multiple_commas).sum()\n",
    "\n",
    "    print(f\"Total comma count: {total_comma_count}\")\n",
    "    return df, total_comma_count\n",
    "\n",
    "\n",
    "def is_undesirable_question_to_count(question):\n",
    "    if isinstance(question, str):\n",
    "        count_phrases = [\n",
    "            \n",
    "            \"what is the title\",\n",
    "            \"what is the research topic\",\n",
    "            \"what data is used in the study\",\n",
    "            \"what data sets are collected in this study\",\n",
    "            \"how did the study\",\n",
    "            \"what does the arrow in figure 6 represent\",\n",
    "            \"what was the publication date of the study\",\n",
    "            \"what is the title of the paper\",\n",
    "            \"what is the purpose of this study\",\n",
    "            \"what was the goal of the study\",\n",
    "            \"what data was utilized in the study\",\n",
    "            \"what is the source of funding for this study\",\n",
    "            \"what was the aim of this study\",\n",
    "            \"what are the objectives of the study\",\n",
    "            \"what was the main focus of the study\",\n",
    "            \"what were the main conclusions of the study\",\n",
    "            \"what methods were used in the study\",\n",
    "            \"what ratio was used for the analysis\",\n",
    "            \"what models are shown in fig 4\",\n",
    "            \"what is the conclusion of this study\",\n",
    "            \"what do the innovations of this study enable\",\n",
    "            \"what is the article about\",\n",
    "            \"what is the doi number for the article\",\n",
    "            \"where can the tool be accessed\",\n",
    "            \"what data has been used\",\n",
    "            \"what were the results of the study\",\n",
    "            \"what are the key findings of this study\",\n",
    "            \"what data sources were used in this study\",\n",
    "            \"what are the limitations of this study\",\n",
    "            \"where was the research conducted\",\n",
    "            \"what are the key words for this article\",\n",
    "            \"what is the main objective of this study\",\n",
    "            \"what evidence supports the research\",\n",
    "            # Add more phrases here\n",
    "        ]\n",
    "        return any(phrase in question.lower() for phrase in count_phrases)\n",
    "    return False\n",
    "\n",
    "def is_truncated(sentence):\n",
    "    \n",
    "    # Ensure the sentence is converted to a string\n",
    "    sentence = str(sentence)\n",
    "    # Define a list of sentence-ending punctuation marks\n",
    "    sentence_endings = ['.', '!', '?', '.\"', '!\"', '?\"', '.”', '!”', '?”']\n",
    "    \n",
    "    # Check if the last character of the sentence is a sentence-ending punctuation mark\n",
    "    if sentence[-1] in sentence_endings:\n",
    "        return False  # Not truncated\n",
    "    else:\n",
    "        #print (\"\\n\" + sentence+\"\\n\")\n",
    "        return True   # Truncated\n",
    "\n",
    "# Assuming you have defined your functions is_undesirable_question_to_count and is_truncated properly\n",
    "\n",
    "def count_truncated_questions_and_answers_in_df(df, filtered_data_file):\n",
    "    #df = pd.read_csv(file_path)\n",
    "    df.info() \n",
    "    columns_with_spaces = df.columns.tolist()\n",
    "    print(columns_with_spaces) \n",
    "    questions = df['Question']\n",
    "    answers = df['Answer']\n",
    "        \n",
    "    questions_count = df['Question'].apply(is_undesirable_question_to_count).sum()\n",
    "\n",
    "    # Count truncated questions\n",
    "    truncated_questions_count = df['Question'].apply(is_truncated).sum()\n",
    "\n",
    "    # Count truncated answers\n",
    "    truncated_answers_count = df['Answer'].apply(is_truncated).sum()\n",
    "     \n",
    "    # Filter out truncated rows\n",
    "    truncated_questions = []\n",
    "    truncated_answers = []\n",
    "    \n",
    "    # Filter out truncated rows\n",
    "    not_truncated_indices = []\n",
    "    for i in range(len(df)):\n",
    "        if not (is_truncated(questions[i]) or is_truncated(answers[i])):\n",
    "            not_truncated_indices.append(i)\n",
    "        else:\n",
    "            if is_truncated(questions[i]):\n",
    "                truncated_questions.append(questions[i])\n",
    "                print(f\"Truncated Question {i}: {questions[i]}\")\n",
    "            if is_truncated(answers[i]):\n",
    "                truncated_answers.append(answers[i])\n",
    "                print(f\"Corresponding Question {i}: {questions[i]}\")\n",
    "                print(f\"Truncated Answer  {i}: {answers[i]} \\n\")\n",
    "    df = df.iloc[not_truncated_indices]\n",
    "      \n",
    "    # Filter out questions and their corresponding answers\n",
    "    filtered_indices = [i for i, question in enumerate(df['Question']) if is_undesirable_question_to_count(question)]\n",
    "    filtered_data = pd.DataFrame({\n",
    "        'Question': df['Question'].iloc[filtered_indices],\n",
    "        'Answer': df['Answer'].iloc[filtered_indices]\n",
    "    })\n",
    "    \n",
    "    # Print the number of rows in the filtered data\n",
    "    print(\"Number of rows in filtered data:\", len(filtered_data))\n",
    "    \n",
    "    # Create a new DataFrame for remaining data without truncated QnA\n",
    "    remaining_indices = [i for i in range(len(df)) if i not in filtered_indices]\n",
    "    remaining_data = df.iloc[remaining_indices]\n",
    "    \n",
    "    # Print the number of rows in the remaining data\n",
    "    print(\"Number of rows in remaining data:\", len(remaining_data))\n",
    "    \n",
    "    # Save the filtered data\n",
    "    filtered_data.to_csv(filtered_data_file, index=False, encoding='utf-8')\n",
    "    \n",
    "    # Save the remaining data\n",
    "    #remaining_data.to_csv(remaining_data_file, index=False, encoding='utf-8')\n",
    "    \n",
    "    return questions_count, truncated_questions_count, truncated_answers_count, remaining_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_filtered_data(file_path, filtered_data):\n",
    "    with open(file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['Question', 'Answer']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(filtered_data)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "def count_errors(text):\n",
    "    tool = language_tool_python.LanguageTool('en-GB')\n",
    "    matches = tool.check(text)\n",
    "    return len(matches)\n",
    "\n",
    "def LanguageTool_df(df):\n",
    "    tool = language_tool_python.LanguageTool('en-GB')\n",
    "    corrected_content = []\n",
    "\n",
    "    original_error_count = 0\n",
    "    corrected_error_count = 0\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        corrected_row = [tool.correct(cell) for cell in df.iloc[i]]\n",
    "        corrected_content.append(corrected_row)\n",
    "\n",
    "        for j in range(len(corrected_content[i])):\n",
    "            original_error_count += count_errors(df.iloc[i, j])\n",
    "            corrected_error_count += count_errors(corrected_content[i][j])\n",
    "            corrected_content[i][j] = corrected_content[i][j].replace(' Answer', 'Answer')\n",
    "            print (corrected_content[i][j])\n",
    "\n",
    "    LanguageTool_corrected_df = pd.DataFrame(corrected_content, columns=df.columns)\n",
    "\n",
    "    return LanguageTool_corrected_df, original_error_count, corrected_error_count\n",
    "\n",
    "\n",
    "def add_space_before_opening_bracket(df):\n",
    "    #df = pd.read_csv(input_file_path)\n",
    "    \n",
    "    for column in df.columns:\n",
    "        df[column] = df[column].apply(lambda cell: re.sub(r'([A-Za-z])\\(', r'\\1 (', cell))\n",
    "    \n",
    "    #df.to_csv(ammended_space_file, index=False)\n",
    "    \n",
    "    return df   # Return the output file path after processing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    # List of CSV files to process\n",
    "    start_time = time.time() \n",
    "    \n",
    "    \n",
    "    \n",
    "    csv_files = [\n",
    "       # \"C:/Users/HP/Documents/Sam/Data Science Voluteer/CSV/Geothermal_energy_wellcome_20230717.csv\",\n",
    "        #\"C:/Users/Joshua Giwa/Downloads/QnAs_generated_27_07_2023/Solar power_wellcome_20230717.csv\",\n",
    "        #\"C:/Users/Joshua Giwa/Downloads/QnAs_generated_27_07_2023/Solar power_gatesopen_20230717.csv\",\n",
    "        #\"C:/Users/Joshua Giwa/Downloads/QnAs_generated_27_07_2023/Geothermal+energy_f1000_20230717.csv\",\n",
    "       # \"C:/Users/Joshua Giwa/Downloads/QnAs_generated_27_07_2023/Geothermal_energy_wellcome_20230717.csv\",\n",
    "       # \"C:/Users/Joshua Giwa/Downloads/QnAs_generated_27_07_2023/Carbon+footprint_wellcome_20230717.csv\",\n",
    "        \"C:/Users/Joshua Giwa/Downloads/test_dataset.csv\"\n",
    "        #\"C:/Users/Joshua Giwa/Downloads/QnAs_generated_26_07_2023/QnA_Biomass_f1000_20230717.csv\"\n",
    "        ## Add more file paths here as needed\n",
    "    ]\n",
    "\n",
    "    total_questions_count = 0\n",
    "    total_truncated_questions_count = 0\n",
    "    total_truncated_answers_count = 0\n",
    "    \n",
    "\n",
    "    for csv_file in csv_files: \n",
    "        df = pd.read_csv(csv_file)\n",
    "       # corrected_file_path = os.path.join(os.path.expanduser(\"~\"), \"Downloads\", os.path.basename(csv_file).replace('.csv', '_corrected.csv'))\n",
    "        #remaining_data_file = os.path.join(os.path.expanduser(\"~\"), \"Downloads\", os.path.basename(csv_file).replace('.csv', '_remaining_data.csv'))\n",
    "        filtered_data_file = os.path.join(os.path.expanduser(\"~\"), \"Downloads\", os.path.basename(csv_file).replace('.csv', '_filtered_questions_non_optimized.csv'))\n",
    "        #ammended_space_file = os.path.join(os.path.expanduser(\"~\"), \"Downloads\", os.path.basename(csv_file).replace('.csv', 'bracket_spaced.csv'))\n",
    "        questions_count, truncated_questions, truncated_answers, remaining_data = count_truncated_questions_and_answers_in_df(df, filtered_data_file)\n",
    "        comma_cluster_removed_df, total_comma_count = comma_cluster_removal_df(remaining_data)\n",
    "        space_before_bracket_ammended_df = add_space_before_opening_bracket(comma_cluster_removed_df)\n",
    "        LanguageTool_corrected_df, original_error_count, corrected_error_count = LanguageTool_df(space_before_bracket_ammended_df)\n",
    "       \n",
    "        \n",
    "        # Save the processed DataFrame with \"updated\" added to the name\n",
    "        cleaned_df = LanguageTool_corrected_df.copy()\n",
    "        cleaned_df_filename = os.path.basename(csv_file).replace('.csv', '_cleaned.csv')\n",
    "\n",
    "        # Assuming that you have a directory where you want to save the updated DataFrames\n",
    "        cleaned_df_dir = os.path.join(os.path.expanduser(\"~\"), \"Downloads\", \"cleaned_QnAs_non_optimized\")\n",
    "\n",
    "        if not os.path.exists(cleaned_df_dir):\n",
    "            os.makedirs(cleaned_df_dir)\n",
    "\n",
    "        cleaned_df_file_path = os.path.join(cleaned_df_dir, cleaned_df_filename)\n",
    "\n",
    "        # Save the updated DataFrame as a CSV file\n",
    "        cleaned_df.to_csv(cleaned_df_file_path, index=False)\n",
    "\n",
    "        # Now, you can use the updated DataFrame for further processing if needed\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        total_questions_count += questions_count\n",
    "        total_truncated_questions_count += truncated_questions\n",
    "        total_truncated_answers_count += truncated_answers\n",
    "        \n",
    "        \n",
    "        print(f\"File: {csv_file}\\n\")\n",
    "        print(f\"Total undesirable questions: {questions_count}\")\n",
    "        print(f\"Total Truncated Questions: {truncated_questions}\")\n",
    "        print(f\"Total Truncated Answers: {truncated_answers}\")\n",
    "        print(f\"Original typo/error found: {original_error_count}\")\n",
    "        print(f\"excessive comma occurence: {total_comma_count}\")\n",
    "        print(f\"Corrected typo/error count: {corrected_errors}\")\n",
    "\n",
    "        \n",
    "        print(f\"(undesirable_questions + Truncated Questions + Truncated Answers + excessive comma occurence + original errer count): {questions_count + truncated_questions + truncated_answers +  total_comma_count + original_error_count}\\n\")\n",
    "\n",
    "  #  print(f\"Total Questions Count: {total_questions_count}\")\n",
    "  #  print(f\"Total Truncated Questions Count: {total_truncated_questions_count}\")\n",
    "  #  print(f\"Total Truncated Answers Count: {total_truncated_answers_count}\")\n",
    "  #  print(f\"Total (Questions + Truncated Questions + Truncated Answers): {total_questions_count + total_truncated_questions_count + total_truncated_answers_count}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    \n",
    "    elapsed_time_seconds = end_time - start_time\n",
    "    elapsed_time_minutes = elapsed_time_seconds / 60\n",
    "\n",
    "    print(f\"Script ran for {elapsed_time_minutes:.2f} minutes.\")\n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    cProfile.run(\"main()\", sort='cumulative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeb4585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7dc079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccf356c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3598587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62f09b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba9a073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d5eaf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54a3395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa97819a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affc19b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5a7e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef246067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a7e662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe5e891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7388faa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd350ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03059844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c532dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6606a597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5153179b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910d86fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906c3f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c7c13a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3611418c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a820334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f03f3ba",
   "metadata": {},
   "source": [
    "###### Deleting the undesirable Questions and thier corresponding answers, and truncated QnAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d784df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf336472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def is_question_to_count(question):\n",
    "    if isinstance(question, str):\n",
    "        count_phrases = [\n",
    "            \n",
    "            \"what is the title\",\n",
    "            \"what is the research topic\",\n",
    "            \"what data is used in the study\",\n",
    "            \"what data sets are collected in this study\",\n",
    "            \"how did the study\",\n",
    "            \"what does the arrow in figure 6 represent\",\n",
    "            \"what was the publication date of the study\",\n",
    "            \"what is the title of the paper\",\n",
    "            \"what is the purpose of this study\",\n",
    "            \"what was the goal of the study\",\n",
    "            \"what data was utilized in the study\",\n",
    "            \"what is the source of funding for this study\",\n",
    "            \"what was the aim of this study\",\n",
    "            \"what are the objectives of the study\",\n",
    "            \"what was the main focus of the study\",\n",
    "            \"what were the main conclusions of the study\",\n",
    "            \"what methods were used in the study\",\n",
    "            \"what ratio was used for the analysis\",\n",
    "            \"what models are shown in fig 4\",\n",
    "            \"what is the conclusion of this study\",\n",
    "            \"what do the innovations of this study enable\",\n",
    "            \"what is the article about\",\n",
    "            \"what is the doi number for the article\",\n",
    "            \"where can the tool be accessed\",\n",
    "            \"what data has been used\",\n",
    "            \"what were the results of the study\",\n",
    "            \"what are the key findings of this study\",\n",
    "            \"what data sources were used in this study\",\n",
    "            \"what are the limitations of this study\",\n",
    "            \"where was the research conducted\",\n",
    "            \"what are the key words for this article\",\n",
    "            \"what is the main objective of this study\",\n",
    "            \"what evidence supports the research\",\n",
    "            # Add more phrases here\n",
    "        ]\n",
    "        return any(phrase in question.lower() for phrase in count_phrases)\n",
    "    return False\n",
    "\n",
    "\n",
    "def is_truncated(text):\n",
    "    if isinstance(text, str):\n",
    "        return text.strip().endswith(\"...\")\n",
    "    return False\n",
    "\n",
    "def is_typo(text):\n",
    "    if isinstance(text, str):\n",
    "        # Here, you can define a list of common words that might indicate typos\n",
    "        # Customize this list according to your needs\n",
    "        common_typos = [\n",
    "            \"odds\", \"noncurrent\", \"(mt)\", \"thermocyling\", \"o2geosocial\", \"Outbreaker2\", \"outbreaker()\", \"avaliable\", \"cleanup\",\n",
    "            \"funannotate\", \"gallic\", \"nonessential\", \"Total\", \"runoff\", \"„\",\n",
    "            # Add more common typos here\n",
    "        ]\n",
    "        return any(typo in text.lower() for typo in common_typos)\n",
    "    return False\n",
    "\n",
    "def filter_undesirable_rows(df):\n",
    "    # Filter rows based on whether the question is undesirable or truncated\n",
    "    is_undesirable_question = df['Question'].apply(is_question_to_count)\n",
    "    is_truncated_question = df['Question'].apply(is_truncated)\n",
    "    is_truncated_answer = df['Answer'].apply(is_truncated)\n",
    "    return df[~is_undesirable_question & ~is_truncated_question or ~is_truncated_answer]\n",
    "\n",
    "def count_typos_in_csv(file_path, column_name):\n",
    "    df = pd.read_csv(file_path)\n",
    "    # Filter out undesirable and truncated rows before counting typos\n",
    "    df_filtered = filter_undesirable_rows(df)\n",
    "    typo_count = df_filtered[column_name].apply(is_typo).sum()\n",
    "    return typo_count\n",
    "\n",
    "def count_questions_in_csv(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    #df.info()\n",
    "    questions_count = df['Question'].apply(is_question_to_count).sum()\n",
    "    return questions_count\n",
    "\n",
    "def count_truncated_questions_and_answers_in_csv(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.info()\n",
    "    questions_count = df['Question'].apply(is_question_to_count).sum()\n",
    "\n",
    "    # Count truncated questions\n",
    "    truncated_questions_count = df['Question'].apply(is_truncated).sum()\n",
    "\n",
    "    # Count truncated answers\n",
    "    truncated_answers_count = df['Answer'].apply(is_truncated).sum()\n",
    "\n",
    "    return questions_count, truncated_questions_count, truncated_answers_count\n",
    "\n",
    "\n",
    "def main():\n",
    "    # List of CSV files to process\n",
    "    csv_files = [\n",
    "        \"C:/Users/Joshua Giwa/Downloads/QnAs_generated_31_07_2023/QnA_Organic farming_f1000_20230730.csv\",\n",
    "        # Add more file paths here as needed\n",
    "    ]\n",
    "\n",
    "    total_typos_count = 0\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        typo_count = count_typos_in_csv(csv_file, 'Question') + count_typos_in_csv(csv_file, 'Answer')\n",
    "        total_typos_count += typo_count\n",
    "\n",
    "        print(f\"File: {csv_file}\")\n",
    "        print(f\"Total Typos: {typo_count}\\n\")\n",
    "\n",
    "        # Load the CSV file again to get the original data\n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "        # Filter out undesirable and truncated rows\n",
    "        df_filtered = filter_undesirable_rows(df)\n",
    "\n",
    "        # Save the cleaned DataFrame back to the CSV file\n",
    "        df_filtered.to_csv(csv_file, index=False)\n",
    "\n",
    "    print(f\"Total Typos Count: {total_typos_count}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4d7a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63930142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f189b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1ea91e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
